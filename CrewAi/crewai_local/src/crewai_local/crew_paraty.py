"""
Sistema de Crews para o Projeto Paraty

Integra os 11 agentes consolidados (v2.0) em 3 workflows principais.
"""

import os
from typing import Dict, Any
from itertools import cycle
from urllib.error import URLError
from urllib.parse import urljoin
from urllib.request import Request, urlopen

from crewai import LLM as CrewLLM
from dotenv import load_dotenv

from .crews.workflow_avaliacao import create_property_evaluation_crew
from .crews.workflow_posicionamento import create_positioning_crew
from .crews.workflow_abertura import create_opening_prep_crew
from .crews.workflow_planejamento_30dias import create_planning_30days_crew
from .owner_profile import get_owner_profile, get_budget_range

load_dotenv()


class _CyclingStaticLLM:
    """LLM est√°tico simples para permitir execu√ß√£o offline."""

    def __init__(self, responses):
        self._responses = cycle(responses)
        self.model = "static-local"

    def call(self, prompt: str, **kwargs: Any) -> str:
        return next(self._responses)

    async def acall(self, prompt: str, **kwargs: Any) -> str:
        return next(self._responses)


def _ollama_available(base_url: str) -> bool:
    """Verifica se o Ollama est√° dispon√≠vel."""
    try:
        ping_url = urljoin(base_url if base_url.endswith("/") else base_url + "/", "api/tags")
        with urlopen(Request(ping_url, method="GET"), timeout=2) as response:
            return response.status == 200
    except (URLError, ValueError):
        return False


def _check_model_available(base_url: str, model_name: str) -> bool:
    """Verifica se um modelo espec√≠fico est√° dispon√≠vel no Ollama."""
    try:
        ping_url = urljoin(base_url if base_url.endswith("/") else base_url + "/", "api/tags")
        with urlopen(Request(ping_url, method="GET"), timeout=2) as response:
            if response.status == 200:
                import json
                data = json.loads(response.read().decode('utf-8'))
                models = [m['name'] for m in data.get('models', [])]
                # Verifica se o modelo existe (com ou sem :latest)
                return any(model_name in m for m in models)
    except Exception:
        pass
    return False


def _get_available_models(base_url: str) -> list:
    """Retorna lista de modelos dispon√≠veis no Ollama."""
    try:
        ping_url = urljoin(base_url if base_url.endswith("/") else base_url + "/", "api/tags")
        with urlopen(Request(ping_url, method="GET"), timeout=2) as response:
            if response.status == 200:
                import json
                data = json.loads(response.read().decode('utf-8'))
                models = []
                for m in data.get('models', []):
                    name = m['name']
                    size = m.get('size', 0)
                    # Converter bytes para GB
                    size_gb = size / (1024**3) if size > 0 else 0
                    models.append({
                        'name': name,
                        'display_name': name,
                        'size_gb': size_gb
                    })
                return models
    except Exception:
        pass
    return []


def _select_model_interactive(base_url: str) -> str:
    """
    Permite ao usu√°rio selecionar o modelo interativamente.
    
    Returns:
        Nome do modelo selecionado (ex: "qwen2.5:14b")
    """
    models = _get_available_models(base_url)
    
    if not models:
        print("‚ö†Ô∏è  Nenhum modelo encontrado no Ollama")
        return None
    
    print("\n" + "="*70)
    print("ü§ñ MODELOS DISPON√çVEIS NO OLLAMA")
    print("="*70)
    
    # Modelos recomendados (em ordem de prefer√™ncia)
    recommended = ["qwen2.5:14b", "glm-4.6:cloud", "llama3.2:latest", "gpt-oss:latest", "deepseek-coder:33b"]
    
    # Organizar modelos: recomendados primeiro, depois outros
    sorted_models = []
    other_models = []
    
    for model in models:
        name = model['name']
        if any(rec in name for rec in recommended):
            sorted_models.append(model)
        else:
            other_models.append(model)
    
    sorted_models.extend(other_models)
    
    # Exibir modelos
    for idx, model in enumerate(sorted_models, 1):
        name = model['name']
        size = model['size_gb']
        
        # Marcar recomendados
        is_recommended = any(rec in name for rec in recommended)
        marker = "‚≠ê" if is_recommended else "  "
        
        print(f"{marker} {idx}. {name:<30} ({size:.1f} GB)")
    
    print("="*70)
    print("\n‚≠ê = Recomendado para este workflow")
    print("\nüí° Recomenda√ß√µes:")
    print("   ‚Ä¢ Qwen2.5 14B: Melhor para tool calling e an√°lise complexa")
    print("   ‚Ä¢ GLM-4.6: √ìtimo equil√≠brio performance/qualidade")
    print("   ‚Ä¢ Llama3.2: R√°pido e eficiente para tasks simples")
    print("\n‚ö†Ô∏è  Modelos N√ÉO recomendados com CrewAI:")
    print("   ‚Ä¢ gpt-oss: Usa 'thinking mode' incompat√≠vel com CrewAI tools")
    print("     (Funciona standalone mas falha em workflows com ferramentas)")
    
    # Solicitar escolha
    while True:
        try:
            choice = input(f"\nEscolha um modelo (1-{len(sorted_models)}) [1]: ").strip()
            
            # Default para primeiro modelo (Qwen2.5 se dispon√≠vel)
            if not choice:
                choice = "1"
            
            idx = int(choice)
            if 1 <= idx <= len(sorted_models):
                selected = sorted_models[idx - 1]
                print(f"\n‚úÖ Modelo selecionado: {selected['name']}")
                return selected['name']
            else:
                print(f"‚ùå Escolha inv√°lida. Digite um n√∫mero entre 1 e {len(sorted_models)}")
        except ValueError:
            print("‚ùå Entrada inv√°lida. Digite um n√∫mero.")
        except KeyboardInterrupt:
            print("\n\n‚ùå Sele√ß√£o cancelada.")
            return None


def _initialize_llm(interactive: bool = True, model_name: str = None):
    """
    Inicializa o LLM.

    Args:
        interactive: Se True, permite sele√ß√£o interativa do modelo
        model_name: Nome espec√≠fico do modelo a ser usado (sobrescreve interactive)

    Returns:
        Inst√¢ncia do LLM configurado
    
    Priority order:
        1. model_name parameter (explicit override)
        2. DEFAULT_MODEL environment variable
        3. Interactive selection (if interactive=True)
        4. Auto-selection fallback (qwen2.5:14b -> glm-4.6 -> gpt-oss)
    """
    base_url = os.getenv("OLLAMA_BASE_URL", "http://localhost:11434")

    if not _ollama_available(base_url):
        print(f"‚ö†Ô∏è  Ollama n√£o dispon√≠vel em {base_url}")
        print(f"‚ö†Ô∏è  Usando modo demonstra√ß√£o (respostas est√°ticas).")

        # Fallback est√°tico com respostas gen√©ricas
        static_responses = [
            "An√°lise realizada com base nos dados fornecidos.",
            "Recomenda√ß√£o: Prosseguir com cautela, considerando os riscos identificados.",
            "Relat√≥rio t√©cnico completo dispon√≠vel nos arquivos de sa√≠da."
        ]

        return _CyclingStaticLLM(static_responses)

    print(f"‚úÖ Conectado ao Ollama em {base_url}")

    # PRIORITY 1: Explicit model_name parameter (API calls, testing overrides)
    if model_name:
        selected_model = model_name
        print(f"üöÄ Usando modelo especificado: {selected_model}")
    # PRIORITY 2: DEFAULT_MODEL environment variable (automation, tests, default config)
    elif os.getenv("DEFAULT_MODEL"):
        selected_model = os.getenv("DEFAULT_MODEL")
        print(f"üöÄ Usando modelo padr√£o (DEFAULT_MODEL): {selected_model}")
    # PRIORITY 3: Interactive selection (manual execution)
    elif interactive:
        selected_model = _select_model_interactive(base_url)
        
        if selected_model:
            print(f"üöÄ Iniciando com modelo: {selected_model}")
            
            # ‚ö†Ô∏è ALERTA: gpt-oss tem formato de resposta incompat√≠vel com CrewAI
            if "gpt-oss" in selected_model.lower():
                print("‚ö†Ô∏è  AVISO: gpt-oss usa 'thinking mode' que pode causar problemas com CrewAI")
                print("‚ö†Ô∏è  Recomenda√ß√£o: Use qwen2.5:14b, glm-4.6:cloud ou llama3.2:latest")
                print("\nüí° gpt-oss funciona bem standalone mas n√£o com ferramentas CrewAI")
                print("   Motivo: CrewAI espera respostas diretas, mas gpt-oss retorna:")
                print("   'Thinking... [racioc√≠nio] ...done thinking. [resposta]'")
                
                cont = input("\n‚ùì Continuar mesmo assim? (pode falhar) [y/N]: ").strip().lower()
                if cont != 'y':
                    print("\nüîÑ Por favor, escolha outro modelo.")
                    return _initialize_llm(interactive=True)
            
            return CrewLLM(model=f"ollama/{selected_model}", base_url=base_url)
    # PRIORITY 4: Auto-selection fallback (no env var, non-interactive mode)
    else:
        # Prioridade 1: Qwen2.5 14B (128k contexto, tool calling excelente)
        if _check_model_available(base_url, "qwen2.5:14b"):
            selected_model = "qwen2.5:14b"
            print(f"üöÄ Usando modelo: Qwen2.5 14B (auto-selecionado)")
        # Prioridade 2: GLM-4.6 (melhor performance, contexto longo)
        elif _check_model_available(base_url, "glm-4.6"):
            selected_model = "glm-4.6:cloud"
            print(f"üîÑ Usando: GLM-4.6 (auto-selecionado)")
        # Fallback: gpt-oss (modelo original)
        else:
            selected_model = "gpt-oss"
            print(f"‚ö†Ô∏è  Usando: gpt-oss (fallback)")
        
        return CrewLLM(model=f"ollama/{selected_model}", base_url=base_url)
    
    # Build and return the LLM instance
    return CrewLLM(model=f"ollama/{selected_model}", base_url=base_url)


def run_property_evaluation():
    """
    Executa o Workflow A: Avalia√ß√£o de Propriedade.
    
    Agentes: Marcelo, Andr√©, Fernando, Ricardo, Gabriel (5 agentes)
    """
    
    print("\nüìã DADOS DA PROPRIEDADE")
    print("-" * 70)
    
    # Exemplo de propriedade (em produ√ß√£o, viria de input do usu√°rio)
    property_data = {
        'name': input("Nome da propriedade: ") or 'Pousada Vista Mar',
        'location': input("Localiza√ß√£o (Centro Hist√≥rico/Praia/etc): ") or 'Centro Hist√≥rico',
        'price': float(input("Pre√ßo de compra (R$): ") or 2_200_000),
        'rooms': int(input("N√∫mero de quartos: ") or 12),
        'capex_estimated': float(input("CAPEX estimado (R$): ") or 280_000),
        'adr_target': float(input("ADR projetado (R$): ") or 320),
        'occupancy_target': float(input("Ocupa√ß√£o projetada (%): ") or 60)
    }
    
    print("\nüöÄ Iniciando avalia√ß√£o com 5 agentes especializados...")
    print("-" * 70)
    
    llm = _initialize_llm()
    crew = create_property_evaluation_crew(llm, property_data)
    
    result = crew.kickoff()
    
    print("\n\n" + "=" * 70)
    print("‚úÖ AVALIA√á√ÉO CONCLU√çDA!")
    print("=" * 70)
    print(result)
    
    # Salvar resultado
    result_text = result.raw if hasattr(result, 'raw') else str(result)
    output_file = f"avaliacao_{property_data['name'].replace(' ', '_')}.md"
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(f"# Avalia√ß√£o: {property_data['name']}\n\n")
        f.write(result_text)
    
    print(f"\nüíæ Resultado salvo em: {output_file}")


def run_positioning_strategy():
    """
    Executa o Workflow B: Estrat√©gia de Posicionamento.
    
    Agentes: Juliana, Marcelo, Helena, Beatriz (4 agentes)
    """
    
    print("\nüìã DADOS DO PROJETO")
    print("-" * 70)
    
    project_data = {
        'location': input("Localiza√ß√£o: ") or 'Paraty - Centro Hist√≥rico',
        'rooms': int(input("N√∫mero de quartos: ") or 12),
        'target_audience': input("P√∫blico-alvo: ") or 'Casais 35-55 anos, alta renda'
    }
    
    print("\nüöÄ Desenvolvendo estrat√©gia de posicionamento...")
    print("-" * 70)
    
    llm = _initialize_llm()
    crew = create_positioning_crew(llm, project_data)
    
    result = crew.kickoff()
    
    print("\n\n" + "=" * 70)
    print("‚úÖ ESTRAT√âGIA DESENVOLVIDA!")
    print("=" * 70)
    print(result)
    
    # Salvar resultado
    result_text = result.raw if hasattr(result, 'raw') else str(result)
    with open("estrategia_posicionamento.md", 'w', encoding='utf-8') as f:
        f.write("# Estrat√©gia de Posicionamento\n\n")
        f.write(result_text)
    
    print("\nüíæ Resultado salvo em: estrategia_posicionamento.md")


def run_opening_preparation():
    """
    Executa o Workflow C: Prepara√ß√£o para Abertura.
    
    Agentes: Paula, Patr√≠cia, Sofia, Renata (4 agentes)
    """
    
    print("\nüìã DADOS DA ABERTURA")
    print("-" * 70)
    
    opening_data = {
        'opening_date': input("Data prevista de abertura (YYYY-MM-DD): ") or '2026-06-01',
        'rooms': int(input("N√∫mero de quartos: ") or 12),
        'staff_size': int(input("Tamanho da equipe: ") or 8)
    }
    
    print("\nüöÄ Preparando para abertura...")
    print("-" * 70)
    
    llm = _initialize_llm()
    crew = create_opening_prep_crew(llm, opening_data)
    
    result = crew.kickoff()
    
    print("\n\n" + "=" * 70)
    print("‚úÖ PLANO DE ABERTURA COMPLETO!")
    print("=" * 70)
    print(result)
    
    # Salvar resultado
    result_text = result.raw if hasattr(result, 'raw') else str(result)
    with open("plano_abertura.md", 'w', encoding='utf-8') as f:
        f.write("# Plano de Abertura\n\n")
        f.write(result_text)
    
    print("\nüíæ Resultado salvo em: plano_abertura.md")


def run_planning_30days():
    """
    Executa o Workflow D: Planejamento Inicial (30 dias).
    
    Agentes: Helena, Ricardo, Juliana, Marcelo (4 agentes)
    """
    
    print("\n" + "=" * 70)
    print("üóìÔ∏è  WORKFLOW D: PLANEJAMENTO INICIAL (30 DIAS)")
    print("=" * 70)
    
    # Carregar perfil do propriet√°rio
    profile = get_owner_profile()
    budget_min, budget_max = get_budget_range()
    
    print("\nüìä PERFIL DO PROPRIET√ÅRIO")
    print("-" * 70)
    print(f"Motiva√ß√£o: {profile['motivacao_principal']}")
    print(f"Budget: R${budget_min:,.0f} - R${budget_max:,.0f}")
    print(f"Horizonte: {profile['horizonte_tempo']}")
    print(f"Break-even m√°ximo: {profile['fluxo_negativo_tolerancia']}")
    print(f"Experi√™ncia hospitalidade: {profile['experiencia_hospitalidade']}")
    print(f"Conhecimento Paraty: {profile['conhecimento_paraty']['nivel']}")
    
    print("\nüìã TAREFAS DO PLANO 30 DIAS")
    print("-" * 70)
    print("‚úì T-1001: Proposta de valor (Helena)")
    print("‚úì T-1010: Mapa competitivo (Juliana)")
    print("‚úì T-1011: Calend√°rio eventos (Marcelo)")
    print("‚úì T-1003: Envelope financeiro (Ricardo)")
    print("‚úì S√≠ntese final (Helena)")
    
    confirma = input("\n‚ñ∂Ô∏è  Iniciar execu√ß√£o? (S/n): ").strip().lower()
    if confirma == 'n':
        print("‚ùå Execu√ß√£o cancelada.")
        return
    
    print("\nüöÄ Iniciando an√°lise estrat√©gica...")
    print("-" * 70)
    
    llm = _initialize_llm()
    
    # Dados do projeto (m√≠nimos necess√°rios)
    project_data = {
        'localizacao': 'Paraty',
        'preferencias_localizacao': ['praia', 'centro_historico'],
        'tamanho_flexivel': True,
        'faixa_quartos': (8, 18)
    }
    
    crew = create_planning_30days_crew(llm, project_data)
    
    result = crew.kickoff()
    
    print("\n\n" + "=" * 70)
    print("‚úÖ PLANO DE 30 DIAS COMPLETO!")
    print("=" * 70)
    print(result)
    
    # Salvar resultado
    result_text = result.raw if hasattr(result, 'raw') else str(result)
    with open("plano_30_dias_resultado.md", 'w', encoding='utf-8') as f:
        f.write("# Plano de 30 Dias - Resultado\n\n")
        f.write("**Data:** " + str(__import__('datetime').date.today()) + "\n\n")
        f.write("## Executive Summary\n\n")
        f.write(result_text)
        f.write("\n\n## Pr√≥ximos Passos\n\n")
        f.write("1. Revisar recomenda√ß√µes de posicionamento\n")
        f.write("2. Validar viabilidade financeira (break-even 6 meses)\n")
        f.write("3. Decidir: Iniciar prospec√ß√£o ativa?\n")
    
    print("\nüíæ Resultado salvo em: plano_30_dias_resultado.md")
    print("\nüìå Pr√≥ximo passo: Revisar documento e tomar Decision Point 1")
    print("   (Aprovar posicionamento e iniciar Fase 3: Pipeline)")


# Mant√©m compatibilidade com c√≥digo antigo
def create_crew():
    """Fun√ß√£o de compatibilidade - usa workflow de avalia√ß√£o por padr√£o."""
    llm = _initialize_llm()
    
    property_data = {
        'name': 'Pousada Exemplo',
        'location': 'Centro Hist√≥rico',
        'price': 2_000_000,
        'rooms': 10,
        'capex_estimated': 250_000,
        'adr_target': 300,
        'occupancy_target': 55
    }
    
    return create_property_evaluation_crew(llm, property_data)
